---
output: 
    pdf_document:
        keep_tex: false
---

<!--HOW TO COMPLETE THIS FORM:-->

<!--
1. Checkboxes in this document appear as follows: 

- [ ] This is a checkbox 

To check a checkbox, replace [ ] by [x], as follows: 

- [x] This is a checked checkbox 

Note that older versions of RStudio (versions lower than 1.3) may not create a formatted checkbox but will leave the original characters, i.e., literally "[ ]" or "[x]". It's fine to submit a PDF in this form.
 
2. For text answers, simply type the relevant text in the areas indicated. A blank line starts a new paragraph. 
 
3. Comments (like these instructions) provide additional instructions throughout the form. There is no need to remove them; they will not appear in the compiled document. 

4. If you are comfortable with Markdown syntax, you may choose to include any Markdown-compliant formatting in the form. For example, you may wish to include R code chunks and compile this document in R Markdown.
-->

This form documents the artifacts associated with the article (i.e., the data and code supporting the computational findings) and describes how to reproduce the findings.


# Part 1: Data

- [ ] This paper does not involve analysis of external data (i.e., no data are used or the only data are generated by the authors via simulation in their code).

<!--
If box above is checked and if no simulated/synthetic data files are provided by the authors, please skip directly to the Code section. Otherwise, continue.
-->

- [x] I certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript.

<!-- If data are simulated using random number generation, please be sure to set the random number seed in the code you provide -->

## Abstract
The dataset consists of observed daily precipitation data in millimeters (mm) from 125 monitoring stations in the Danube river basin (Europe) and from 2229 monitoring stations in the Mississippi river basin (North America) over the period from 1965 to 2020. The temperature covariate in Celsius degree used to fit the model in this project was derived from the ERA5-Land reanalysis data for the corresponding region we selected, which is a global land-surface dataset with a high spatial resolution of 9km, and the projected temperature covariate is derived from climate models outputs of the sixth Coupled Model Intercomparison Project (CMIP6), namely AWI, MIROC, and MPI.

<!--
Provide a short (< 100 words), high-level description of the data
-->

## Availability


- [x] Data **are** publicly available.
- [ ] Data **cannot be made** publicly available.

If the data are publicly available, see the *Publicly available data* section. Otherwise, see the *Non-publicly available data* section, below.

### Publicly available data

- [x] Data are available online at:
* Climate model outputs and EAR5-Land Reanalysis data: https://www.copernicus.eu/en/access-data
* Precipitation observations: https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily
* Watershed Boundary Dataset: https://www.usgs.gov/national-hydrography/watershed-boundary-dataset
* The data files for plots are stored in Github repository: https://github.com/PangChung/ExtremePrecip/
- [ ] Data are available as part of the paper’s supplementary material.

- [ ] Data are publicly available by request, following the process described here:

- [x] Data are or will be made available through some other mechanism, described here:
* We have saved the data used in our marginal modeling and dependence modeling in the format of R data file (.RData), and we host those data on Github[https://github.com/PangChung/ExtremePrecip] under the folder ``data'', which are public accessible. Though the raw data of the EAR5-Land Reanalysis data from which we derived the temperature covariate in Celsius degree can be downloaded from the website https://www.copernicus.eu/en/access-data, this raw data will be provided upon email request as the size of it is hundreds of gigabytes and it will take great efforts for someone to download directly from the Copernicus website. The email address is peng[dot]zhong[at]unsw[dot]edu[dot]au. 

<!-- If data are available by request to the authors or some other data owner, please make sure to explain the process of requesting access to the data. -->

### Non-publicly available data

<!--
The Journal of the American Statistical Association requires authors to make data accompanying their papers available to the scientific community except in cases where: 1) public sharing of data would be impossible, 2) suitable synthetic data are provided which allow the main analyses to be replicated (recognizing that results may differ from the "real" data analyses), and 3) the scientific value of the results and methods outweigh the lack of reproducibility.

Please discuss the lack of publicly available data. For example:
-	why data sharing is not possible,
-	what synthetic data are provided, and 
-	why the value of the paper's scientific contribution outweighs the lack of reproducibility.
-->

## Description

### File format(s)

<!--
Check all that apply
-->
- [ ] CSV or other plain text.
- [x] Software-specific binary format (.Rda, Python pickle, etc.): .Rda (.RData)
- [ ] Standardized binary format (e.g., netCDF, HDF5, etc.): 
- [ ] Other (please specify):

### Data dictionary

<!--
A data dictionary provides information that allows users to understand the meaning, format, and use of the data.
-->

- [x] Provided by authors in the following file(s):
* `data/precip.RData`: The precipitation data for the eight subregions, which contain `R` objects:
   + `precip`: Lists of lists, raw data of the precipitation in millimeters (mm) in 8 subregions. This is the response variable used in the marginal fit and dependence fit.
   + `region.name`: a vector, names of the 8 subregions
   + `region.id`: a vector, regional ID number that corresponding to the regional number in the shapefiles.
   + `station`: a data frame, contains geographical information about the monitoring stations, where the precipitation data were recorded. The ``X'' column is latitude degrees, the ``Y'' column is the longitude in degrees, the ``start'' column is the start measuring year, the ``end'' is the last measuring year, the ``elev'' is the elevation of the monitoring stations in meters, and the ``group.id'' corresponds to the region.id for identifying each of the 8 subregions.
   + `START.date and END.date`: dates, between which the data were used in our analysis. 
* `data/temperature.RData`: The derived temperature covariate over the period 1965--2020, which contains `R` objects:
    + `date.df`: data frame, contains the date between 1965--2020, and its corresponding season of the year. 
    + `temperature.covariate`: list of vectors, the derived temperature covariate (30 day moving averages) used in marginal modeling and dependence modeling.
    + `temperature`: list of vectors, daily spatial temperature avarages in Celsius degrees, used only during data preprocessing. 
    + `loc_df`: geographical information about the locations of the ERA5-Land temperature data, used only during data preprocessing. 
* `data/temperature_pred.RData`: The derived temperature covariate from the climate models over the period 2015--2100 under different shared socioeconomic pathways (SSP 2-4.5 or SSP 5-8.5), which contains `R` objects:
    + `date.245 and date.585`: vector of dates, corresponding to the temperature covariate from the climate models. 
    + `idx.models`: 5 climate models, we used the first, the 3rd, and the 4th for future projections, which are denoted by AWI, MIROC, and MPI. 
    + `temperature.245.avg and temperature.585.avg`: lists of list, each list contains the derived temperature covariate in Celsius degrees from one climate model for future projections before realign with the temperature covariate derived from the ERA5-Land data under SSP 2-4.5 (or SSP 5-8.5). SSP 2-4.5 is denoted by 245, and the same goes for SSP 5-8.5.    
* `data/marginal_fit_quantiles.RData`: Transformed margins based on the marginal fit,  which contains `R` objects:
    + `theretical.quantiles`: list of matrices, each matrix corresponding to the fitted marginal data based on the marginal model fit for each subregion, this is only used to generate the QQplots in the manuscript. 
* `data/dep.fit.boot.results3.RData`: Fitted results from the bootstrap scheme for the dependence model, which contains `R` objects:
    + `boot.result.df`: data frame, contains the 95\% confidence interval (e.g, the column low.shape, high.shape) based on the bootstrap for each season, each region, and each risk functional.
    + `boot.result.list`:  lists of lists for each risk functional (first dim), each season (second dim) and each subregion (third dim). In each list, it contains the standard error of the three parameter estimates, the estimates using the whole data set, and the 300 nonparametric bootstrap estimates, named by jack.
* `data/era5_geoinfo.RData`: Shapefiles for the 8 subregions, which contains `R` objects:
    + `shape1`: shapefile of the US river-basins.
    + `shape3`: shapefile of Danube river-basin.
* `data/transformed_coordinates.RData`: Transformed coordinates for the eight subregions, which transformed the latitude/longitude coordinate to the Euclidean coordinate and contains `R` objects:  
    + `loc.trans.list`: list of matrices: transformed coordinates for each of the 8 subregions in meters. 
- [ ] Data file(s) is(are) self-describing (e.g., netCDF files)
- [x] Available at the following URL: 
* Github: https://github.com/PangChung/ExtremePrecip/

### Additional Information (optional)

<!-- 
OPTIONAL: Provide any additional details that would be helpful in understanding the data. If relevant, please provide unique identifier/DOI/version information and/or license/terms of use.
-->

# Part 2: Code

## Abstract
The code contains all the code to process the raw data (upon request) and generate all the figures and tables in the main manuscript and the supplemental material from the .RData files provided. The `R` script file `code/bootstrap.R` is used to fit the marginal model as well as the dependence model when the variable `bootstrap.ind=0`, otherwise, it will fit the marginal model together with the dependence model to the bootstrap data when the variable `bootstrap.ind !=0`. To generate all the figures, one can use and follow the `R` script `code/plots.R`. We also created a `R` markdown file `ResultsReproduction.Rmd` to help readers learn how to reproduce the results presented in this manuscript.

<!--
Provide a short (< 100 words), high-level description of the code. If necessary, more details can be provided in files that accompany the code. If no code is provided, please state this and say why (e.g., if the paper contains no computational work).
-->

## Description

### Code format(s)

<!--
Check all that apply
-->
- [x] Script files
    - [x] R
    - [ ] Python
    - [ ] Matlab
    - [ ] Other: 
- [x] Package
    - [x] R
    - [ ] Python
    - [ ] MATLAB toolbox
    - [ ] Other: 
- [ ] Reproducible report 
    - [ ] R Markdown
    - [ ] Jupyter notebook
    - [ ] Other:
- [x] Shell script
- [ ] Other (please specify): 

### Supporting software requirements
* de Fondeville R, Belzile L (2023). _mvPot: Multivariate Peaks-over-Threshold Modelling for Spatial Extreme Events_. `R` package version 0.1.6,<https://CRAN.R-project.org/package=mvPot>.
* Youngman BD (2022). “evgam: An R Package for Generalized Additive Extreme Value Models.” _Journal of Statistical Software_, *103*(3), 1-26. doi:10.18637/jss.v103.i03 <https://doi.org/10.18637/jss.v103.i03>.
<!--
Please cite all software packages in the References Section in similar fashion to paper citations, citing packages that are foundational to the research outcome (including packages that implement methods to which you compare your methods). You may elect to not cite packages used for supporting purposes. For R packages, note that running `citation('name_of_package')` often shows how the package authors wish to be cited. 
-->

#### Version of primary software used
* `R` version 4.3.2
* `OpenPBS` 23.06.06
<!--
(e.g., R version 3.6.0)
-->

#### Libraries and dependencies used by the code
* `R` packages:
    + `mvPotST` (a spatial-temporal version of `mvPot` version 0.1.6,  
    located at `code/archived/mvPotST/mvPotST_0.0.0.9000.tar.gz` in the Github repository.)
    + `evgam` version 1.0.0
    + `mgcv` version 1.9-0
    + `evd` version 2.3-6.1  
    + `lubridate` version 1.9.3 
    + `ggplot2` version 3.5.0
    + `ggpubr` version 0.6.0 
    + `gridExtra` version 2.3
   
<!--
Include version numbers (e.g., version numbers for any R or Python packages used)
-->

### Supporting system/hardware requirements (optional)
Access to HPC with OpenPBS management software. 
<!--
OPTIONAL: System/hardware requirements including operating system with version number, access to cluster, GPUs, etc.
-->

### Parallelization used

- [ ] No parallel code used
- [ ] Multi-core parallelization on a single machine/node
    - Number of cores used: 
- [x] Multi-machine/multi-node parallelization 
    - Number of nodes and cores used: 56 nodes with 16 cores on each nodes

### License

- [x] MIT License (default)
- [ ] BSD 
- [ ] GPL v3.0
- [ ] Creative Commons
- [ ] Other: (please specify)


### Additional information (optional)

<!--
OPTIONAL: By default, submitted code will be published on the JASA GitHub repository (http://github.com/JASA-ACS) as well as in the supplementary material. Authors are encouraged to also make their code available in a public code repository, such as on GitHub, GitLab, or BitBucket. If relevant, please provide unique identifier/DOI/version information (e.g., a Git commit ID, branch, release, or tag). If the code and workflow are provided together, this section may be omitted, with information provided in the "Location" section below.
-->

# Part 3: Reproducibility workflow
<!--
The materials provided should provide a straightforward way for reviewers and readers to reproduce analyses with as few steps as possible. 
-->

## Scope

The provided workflow reproduces:

- [ ] Any numbers provided in text in the paper
- [x] The computational method(s) presented in the paper (i.e., code is provided that implements the method(s))
- [x] All tables and figures in the paper
- [ ] Selected tables and figures in the paper, as explained and justified below:

## Workflow

### Location

The workflow is available:

<!--
Check all that apply, and in the case of a Git repository include unique identifier, such as specific commit ID, branch, release, or tag.
-->
- [ ] As part of the paper’s supplementary material.
- [x] In this Git repository: https://github.com/PangChung/ExtremePrecip
- [ ] Other (please specify):

<!--
Indicate where the materials (generally including the code, unless in a separate location and indicated in the previous section) are available. We strongly encourage authors to place their materials (but not large datasets) in a Git repository hosted on a site such as GitHub, GitLab, or BitBucket. If the repository is private during the review process, please indicate the location where it will be available publicly upon publication, and also include the materials as a zip file (e.g., obtained directly from the Git hosting site) as supplementary materials.
-->


### Format(s)

<!--
Check all that apply
-->
- [ ] Single master code file 
- [ ] Wrapper (shell) script(s)
- [x] Self-contained R Markdown file, Jupyter notebook, or other literate programming approach
- [ ] Text file (e.g., a readme-style file) that documents workflow
- [ ] Makefile
- [ ] Other (more detail in *Instructions* below)

### Instructions
Download the Github repository to your local machine, and see the `R` markdown file `ResultsReproduction.Rmd` to learn how to reproduce the results and all the figures presented in the manuscript.
<!--
Describe how to use the materials provided to reproduce analyses in the manuscript. Additional details can be provided in file(s) accompanying the reproducibility materials. If no workflow is provided, please state this and say why (e.g., if the paper contains no computational work).
-->

### Expected run-time

Approximate time needed to reproduce the analyses on a standard desktop machine:

- [ ] < 1 minute
- [ ] 1-10 minutes
- [ ] 10-60 minutes
- [ ] 1-8 hours
- [ ] > 8 hours
- [x] Not feasible to run on a desktop machine, as described here:
We use a computer cluster with 56 nodes to do the nonparametric bootstrap. However, one is still able to use a multicore workstation to fit the model for individual subregion within several hours. 

### Additional information (optional)

<!--
OPTIONAL: Additional documentation provided (e.g., R package vignettes, demos or other examples) that show how to use the provided code/software in other settings.
-->

# Notes (optional)

<!--
OPTIONAL: Any other relevant information not covered on this form. If reproducibility materials are not publicly available at the time of submission, please provide information here on how the reviewers can view the materials.
-->
